{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from dalab import read_pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langdetect import detect\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from time import time\n",
    "import keras\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, SimpleRNN, GRU, LSTM\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2841</th>\n",
       "      <td>machine_learning</td>\n",
       "      <td>this article will portray how data related to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10162</th>\n",
       "      <td>ai</td>\n",
       "      <td>dear friends, i’m thrilled to announce i am j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>machine_learning</td>\n",
       "      <td>tl; dr: you can think of machine learning alg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>deep_learning</td>\n",
       "      <td>the question that i get the most from new and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>convolution_neural</td>\n",
       "      <td>with the rapid advances in ai/ml, it is very ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    class                                              story\n",
       "2841     machine_learning   this article will portray how data related to...\n",
       "10162                  ai   dear friends, i’m thrilled to announce i am j...\n",
       "3332     machine_learning   tl; dr: you can think of machine learning alg...\n",
       "5641        deep_learning   the question that i get the most from new and...\n",
       "7372   convolution_neural   with the rapid advances in ai/ml, it is very ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/medium_stories/dataframes/en_lower_stories.pickle').reset_index(drop=True)\n",
    "df = df.sample(frac=1)\n",
    "df = df.drop_duplicates(subset='story')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine_learning 834\n",
      "ai 824\n",
      "deep_learning 770\n",
      "convolution_neural 194\n",
      "web_scrape 188\n",
      "big_data 521\n",
      "data_extraction 354\n",
      "web_crawling 147\n",
      "transfer_learning 498\n",
      "_speech_recognition 492\n",
      "reinforcement_learning 163\n",
      "data_science 823\n",
      "web_scraping 464\n",
      "artificial_intelligence 665\n",
      "machine_translation 271\n",
      "computer_vision 792\n",
      "web_crawler 227\n",
      "genetic_algorithm 226\n",
      "neural_network 210\n",
      "natural_language_processing 578\n",
      "intelligent_machine 220\n",
      "nlp 657\n",
      "time_series 769\n",
      "data_mining 464\n",
      "recurrent_neural 365\n",
      "data_engineering 406\n",
      "image_understanding 121\n",
      "genetic_programming 63\n",
      "pattern_recognition 72\n",
      "evolutionary_computation 17\n",
      "object_recognition 107\n",
      "speech_processing 7\n"
     ]
    }
   ],
   "source": [
    "for topic in df['class'].unique():\n",
    "    print(topic, len(df[df['class'] == topic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 1000\n",
    "VOCAB_SIZE = 20000\n",
    "TRAIN_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = word_tokenize(' '.join(df.story.tolist()))\n",
    "word_counts = Counter(all_words).most_common(VOCAB_SIZE)\n",
    "words = [w[0] for w in word_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n"
     ]
    }
   ],
   "source": [
    "embed_dic = {}\n",
    "for index, word in enumerate(words):\n",
    "    if index % 500 == 0: print(index)\n",
    "    token = nlp(word)\n",
    "    embed_dic[token.text] = token.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.671140</td>\n",
       "      <td>-0.475781</td>\n",
       "      <td>1.225882</td>\n",
       "      <td>-0.533356</td>\n",
       "      <td>1.413614</td>\n",
       "      <td>2.528172</td>\n",
       "      <td>-0.030113</td>\n",
       "      <td>0.486537</td>\n",
       "      <td>3.412096</td>\n",
       "      <td>1.299003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361494</td>\n",
       "      <td>0.078374</td>\n",
       "      <td>-0.094767</td>\n",
       "      <td>-0.087820</td>\n",
       "      <td>-0.176552</td>\n",
       "      <td>0.149058</td>\n",
       "      <td>0.224980</td>\n",
       "      <td>-0.329079</td>\n",
       "      <td>0.187947</td>\n",
       "      <td>-0.189483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>1.499199</td>\n",
       "      <td>-0.151666</td>\n",
       "      <td>2.150062</td>\n",
       "      <td>1.835209</td>\n",
       "      <td>1.904099</td>\n",
       "      <td>2.142193</td>\n",
       "      <td>-1.108657</td>\n",
       "      <td>-1.281631</td>\n",
       "      <td>2.732129</td>\n",
       "      <td>2.948512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079698</td>\n",
       "      <td>-0.464941</td>\n",
       "      <td>1.290173</td>\n",
       "      <td>0.061074</td>\n",
       "      <td>-0.257399</td>\n",
       "      <td>-0.752442</td>\n",
       "      <td>0.019620</td>\n",
       "      <td>0.132082</td>\n",
       "      <td>-0.440150</td>\n",
       "      <td>-0.476223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>0.630779</td>\n",
       "      <td>1.138584</td>\n",
       "      <td>2.530838</td>\n",
       "      <td>0.166183</td>\n",
       "      <td>3.076835</td>\n",
       "      <td>0.542186</td>\n",
       "      <td>-0.858887</td>\n",
       "      <td>0.884039</td>\n",
       "      <td>2.754835</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297402</td>\n",
       "      <td>-0.254304</td>\n",
       "      <td>1.426802</td>\n",
       "      <td>-0.010306</td>\n",
       "      <td>-0.657113</td>\n",
       "      <td>-0.627469</td>\n",
       "      <td>0.097199</td>\n",
       "      <td>-0.183204</td>\n",
       "      <td>-0.213610</td>\n",
       "      <td>-0.170229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>2.040906</td>\n",
       "      <td>0.173398</td>\n",
       "      <td>2.365521</td>\n",
       "      <td>-1.138491</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>2.351219</td>\n",
       "      <td>-2.068765</td>\n",
       "      <td>-0.857941</td>\n",
       "      <td>0.967327</td>\n",
       "      <td>2.126300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.527834</td>\n",
       "      <td>-0.229152</td>\n",
       "      <td>-0.059828</td>\n",
       "      <td>0.299519</td>\n",
       "      <td>-0.925737</td>\n",
       "      <td>-0.175775</td>\n",
       "      <td>0.280792</td>\n",
       "      <td>0.260768</td>\n",
       "      <td>0.674299</td>\n",
       "      <td>0.673200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&amp;</th>\n",
       "      <td>-0.362176</td>\n",
       "      <td>-1.536422</td>\n",
       "      <td>0.681592</td>\n",
       "      <td>-0.254282</td>\n",
       "      <td>-0.020795</td>\n",
       "      <td>2.549080</td>\n",
       "      <td>1.063519</td>\n",
       "      <td>1.306450</td>\n",
       "      <td>1.050382</td>\n",
       "      <td>2.485573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.431890</td>\n",
       "      <td>-0.154748</td>\n",
       "      <td>-0.647066</td>\n",
       "      <td>-0.048509</td>\n",
       "      <td>0.023910</td>\n",
       "      <td>-0.560396</td>\n",
       "      <td>0.427393</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.882393</td>\n",
       "      <td>-0.388471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'</th>\n",
       "      <td>-1.620776</td>\n",
       "      <td>2.052795</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>-0.315580</td>\n",
       "      <td>0.532586</td>\n",
       "      <td>-0.451270</td>\n",
       "      <td>-1.238636</td>\n",
       "      <td>0.606207</td>\n",
       "      <td>-0.797014</td>\n",
       "      <td>0.126661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054849</td>\n",
       "      <td>-0.057004</td>\n",
       "      <td>0.090347</td>\n",
       "      <td>-0.235629</td>\n",
       "      <td>-0.785747</td>\n",
       "      <td>-0.306805</td>\n",
       "      <td>0.576140</td>\n",
       "      <td>0.273453</td>\n",
       "      <td>0.878228</td>\n",
       "      <td>0.013317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>''</th>\n",
       "      <td>-1.888850</td>\n",
       "      <td>-0.329437</td>\n",
       "      <td>2.229829</td>\n",
       "      <td>-0.024572</td>\n",
       "      <td>0.612867</td>\n",
       "      <td>1.830826</td>\n",
       "      <td>-2.658098</td>\n",
       "      <td>1.066225</td>\n",
       "      <td>-0.894128</td>\n",
       "      <td>0.677597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093398</td>\n",
       "      <td>-0.030841</td>\n",
       "      <td>-0.173364</td>\n",
       "      <td>-0.138874</td>\n",
       "      <td>-0.683034</td>\n",
       "      <td>-0.094501</td>\n",
       "      <td>0.465635</td>\n",
       "      <td>0.371119</td>\n",
       "      <td>0.759352</td>\n",
       "      <td>0.149494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'d</th>\n",
       "      <td>-2.117164</td>\n",
       "      <td>-1.338601</td>\n",
       "      <td>0.084229</td>\n",
       "      <td>0.462426</td>\n",
       "      <td>-1.943431</td>\n",
       "      <td>-0.868539</td>\n",
       "      <td>-1.988568</td>\n",
       "      <td>-1.283501</td>\n",
       "      <td>1.316628</td>\n",
       "      <td>1.031664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245045</td>\n",
       "      <td>0.218747</td>\n",
       "      <td>-0.037458</td>\n",
       "      <td>-0.123892</td>\n",
       "      <td>-0.492345</td>\n",
       "      <td>-0.260605</td>\n",
       "      <td>0.047124</td>\n",
       "      <td>-0.004179</td>\n",
       "      <td>0.792069</td>\n",
       "      <td>-0.005892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'ll</th>\n",
       "      <td>-1.817729</td>\n",
       "      <td>-0.345378</td>\n",
       "      <td>0.854443</td>\n",
       "      <td>0.764095</td>\n",
       "      <td>-1.413824</td>\n",
       "      <td>-0.242263</td>\n",
       "      <td>-2.870903</td>\n",
       "      <td>1.914835</td>\n",
       "      <td>1.601110</td>\n",
       "      <td>1.654043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297578</td>\n",
       "      <td>0.113090</td>\n",
       "      <td>0.135073</td>\n",
       "      <td>-0.587226</td>\n",
       "      <td>-0.076004</td>\n",
       "      <td>0.153083</td>\n",
       "      <td>0.157968</td>\n",
       "      <td>0.446649</td>\n",
       "      <td>0.510730</td>\n",
       "      <td>0.062492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'m</th>\n",
       "      <td>0.698488</td>\n",
       "      <td>-0.773644</td>\n",
       "      <td>0.095428</td>\n",
       "      <td>1.951090</td>\n",
       "      <td>1.801322</td>\n",
       "      <td>-0.856540</td>\n",
       "      <td>-1.032917</td>\n",
       "      <td>-1.498475</td>\n",
       "      <td>0.703896</td>\n",
       "      <td>0.657627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308484</td>\n",
       "      <td>0.174957</td>\n",
       "      <td>0.140864</td>\n",
       "      <td>-0.164224</td>\n",
       "      <td>-0.266943</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.262934</td>\n",
       "      <td>0.027962</td>\n",
       "      <td>0.889033</td>\n",
       "      <td>-0.010744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "!    0.671140 -0.475781  1.225882 -0.533356  1.413614  2.528172 -0.030113   \n",
       "#    1.499199 -0.151666  2.150062  1.835209  1.904099  2.142193 -1.108657   \n",
       "$    0.630779  1.138584  2.530838  0.166183  3.076835  0.542186 -0.858887   \n",
       "%    2.040906  0.173398  2.365521 -1.138491  0.034594  2.351219 -2.068765   \n",
       "&   -0.362176 -1.536422  0.681592 -0.254282 -0.020795  2.549080  1.063519   \n",
       "'   -1.620776  2.052795  0.476201 -0.315580  0.532586 -0.451270 -1.238636   \n",
       "''  -1.888850 -0.329437  2.229829 -0.024572  0.612867  1.830826 -2.658098   \n",
       "'d  -2.117164 -1.338601  0.084229  0.462426 -1.943431 -0.868539 -1.988568   \n",
       "'ll -1.817729 -0.345378  0.854443  0.764095 -1.413824 -0.242263 -2.870903   \n",
       "'m   0.698488 -0.773644  0.095428  1.951090  1.801322 -0.856540 -1.032917   \n",
       "\n",
       "          7         8         9      ...          374       375       376  \\\n",
       "!    0.486537  3.412096  1.299003    ...     0.361494  0.078374 -0.094767   \n",
       "#   -1.281631  2.732129  2.948512    ...     0.079698 -0.464941  1.290173   \n",
       "$    0.884039  2.754835 -0.390936    ...     0.297402 -0.254304  1.426802   \n",
       "%   -0.857941  0.967327  2.126300    ...    -0.527834 -0.229152 -0.059828   \n",
       "&    1.306450  1.050382  2.485573    ...    -0.431890 -0.154748 -0.647066   \n",
       "'    0.606207 -0.797014  0.126661    ...     0.054849 -0.057004  0.090347   \n",
       "''   1.066225 -0.894128  0.677597    ...    -0.093398 -0.030841 -0.173364   \n",
       "'d  -1.283501  1.316628  1.031664    ...     0.245045  0.218747 -0.037458   \n",
       "'ll  1.914835  1.601110  1.654043    ...     0.297578  0.113090  0.135073   \n",
       "'m  -1.498475  0.703896  0.657627    ...     0.308484  0.174957  0.140864   \n",
       "\n",
       "          377       378       379       380       381       382       383  \n",
       "!   -0.087820 -0.176552  0.149058  0.224980 -0.329079  0.187947 -0.189483  \n",
       "#    0.061074 -0.257399 -0.752442  0.019620  0.132082 -0.440150 -0.476223  \n",
       "$   -0.010306 -0.657113 -0.627469  0.097199 -0.183204 -0.213610 -0.170229  \n",
       "%    0.299519 -0.925737 -0.175775  0.280792  0.260768  0.674299  0.673200  \n",
       "&   -0.048509  0.023910 -0.560396  0.427393  0.642400  0.882393 -0.388471  \n",
       "'   -0.235629 -0.785747 -0.306805  0.576140  0.273453  0.878228  0.013317  \n",
       "''  -0.138874 -0.683034 -0.094501  0.465635  0.371119  0.759352  0.149494  \n",
       "'d  -0.123892 -0.492345 -0.260605  0.047124 -0.004179  0.792069 -0.005892  \n",
       "'ll -0.587226 -0.076004  0.153083  0.157968  0.446649  0.510730  0.062492  \n",
       "'m  -0.164224 -0.266943  0.071756  0.262934  0.027962  0.889033 -0.010744  \n",
       "\n",
       "[10 rows x 384 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_words = pd.DataFrame(embed_dic).T\n",
    "embed_words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;PAD&gt;</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>0.671140</td>\n",
       "      <td>-0.475781</td>\n",
       "      <td>1.225882</td>\n",
       "      <td>-0.533356</td>\n",
       "      <td>1.413614</td>\n",
       "      <td>2.528172</td>\n",
       "      <td>-0.030113</td>\n",
       "      <td>0.486537</td>\n",
       "      <td>3.412096</td>\n",
       "      <td>1.299003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361494</td>\n",
       "      <td>0.078374</td>\n",
       "      <td>-0.094767</td>\n",
       "      <td>-0.087820</td>\n",
       "      <td>-0.176552</td>\n",
       "      <td>0.149058</td>\n",
       "      <td>0.224980</td>\n",
       "      <td>-0.329079</td>\n",
       "      <td>0.187947</td>\n",
       "      <td>-0.189483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>1.499199</td>\n",
       "      <td>-0.151666</td>\n",
       "      <td>2.150062</td>\n",
       "      <td>1.835209</td>\n",
       "      <td>1.904099</td>\n",
       "      <td>2.142193</td>\n",
       "      <td>-1.108657</td>\n",
       "      <td>-1.281631</td>\n",
       "      <td>2.732129</td>\n",
       "      <td>2.948512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079698</td>\n",
       "      <td>-0.464941</td>\n",
       "      <td>1.290173</td>\n",
       "      <td>0.061074</td>\n",
       "      <td>-0.257399</td>\n",
       "      <td>-0.752442</td>\n",
       "      <td>0.019620</td>\n",
       "      <td>0.132082</td>\n",
       "      <td>-0.440150</td>\n",
       "      <td>-0.476223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>0.630779</td>\n",
       "      <td>1.138584</td>\n",
       "      <td>2.530838</td>\n",
       "      <td>0.166183</td>\n",
       "      <td>3.076835</td>\n",
       "      <td>0.542186</td>\n",
       "      <td>-0.858887</td>\n",
       "      <td>0.884039</td>\n",
       "      <td>2.754835</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297402</td>\n",
       "      <td>-0.254304</td>\n",
       "      <td>1.426802</td>\n",
       "      <td>-0.010306</td>\n",
       "      <td>-0.657113</td>\n",
       "      <td>-0.627469</td>\n",
       "      <td>0.097199</td>\n",
       "      <td>-0.183204</td>\n",
       "      <td>-0.213610</td>\n",
       "      <td>-0.170229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>2.040906</td>\n",
       "      <td>0.173398</td>\n",
       "      <td>2.365521</td>\n",
       "      <td>-1.138491</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>2.351219</td>\n",
       "      <td>-2.068765</td>\n",
       "      <td>-0.857941</td>\n",
       "      <td>0.967327</td>\n",
       "      <td>2.126300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.527834</td>\n",
       "      <td>-0.229152</td>\n",
       "      <td>-0.059828</td>\n",
       "      <td>0.299519</td>\n",
       "      <td>-0.925737</td>\n",
       "      <td>-0.175775</td>\n",
       "      <td>0.280792</td>\n",
       "      <td>0.260768</td>\n",
       "      <td>0.674299</td>\n",
       "      <td>0.673200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "<PAD>  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "!      0.671140 -0.475781  1.225882 -0.533356  1.413614  2.528172 -0.030113   \n",
       "#      1.499199 -0.151666  2.150062  1.835209  1.904099  2.142193 -1.108657   \n",
       "$      0.630779  1.138584  2.530838  0.166183  3.076835  0.542186 -0.858887   \n",
       "%      2.040906  0.173398  2.365521 -1.138491  0.034594  2.351219 -2.068765   \n",
       "\n",
       "            7         8         9      ...          374       375       376  \\\n",
       "<PAD>  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "!      0.486537  3.412096  1.299003    ...     0.361494  0.078374 -0.094767   \n",
       "#     -1.281631  2.732129  2.948512    ...     0.079698 -0.464941  1.290173   \n",
       "$      0.884039  2.754835 -0.390936    ...     0.297402 -0.254304  1.426802   \n",
       "%     -0.857941  0.967327  2.126300    ...    -0.527834 -0.229152 -0.059828   \n",
       "\n",
       "            377       378       379       380       381       382       383  \n",
       "<PAD>  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "!     -0.087820 -0.176552  0.149058  0.224980 -0.329079  0.187947 -0.189483  \n",
       "#      0.061074 -0.257399 -0.752442  0.019620  0.132082 -0.440150 -0.476223  \n",
       "$     -0.010306 -0.657113 -0.627469  0.097199 -0.183204 -0.213610 -0.170229  \n",
       "%      0.299519 -0.925737 -0.175775  0.280792  0.260768  0.674299  0.673200  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding = pd.DataFrame({'<PAD>': np.zeros(shape=[1,embed_words.shape[1]])[0]}).T\n",
    "embed_matrix = padding.append(embed_words)\n",
    "embed_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {j:i+1 for i,j in enumerate(embed_matrix.index.tolist()[1:])}\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.word_index = word_index\n",
    "sequences = tokenizer.texts_to_sequences(df.story)\n",
    "data = pad_sequences(sequences, maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_matrix = np.random.randn(embed_matrix.shape[0], embed_matrix.shape[1])\n",
    "random_matrix[0] = np.zeros([1, embed_matrix.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot = pd.get_dummies(df['class'])\n",
    "target_labels = onehot.columns\n",
    "target = onehot.as_matrix()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[:TRAIN_SIZE]\n",
    "x_test = data[TRAIN_SIZE:]\n",
    "\n",
    "y_train = target[:TRAIN_SIZE]\n",
    "y_test = target[TRAIN_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10007 samples, validate on 2502 samples\n",
      "Epoch 1/2\n",
      "10007/10007 [==============================] - 367s - loss: 3.2068 - acc: 0.0701 - val_loss: 3.0059 - val_acc: 0.1299\n",
      "Epoch 2/2\n",
      "10007/10007 [==============================] - 333s - loss: 2.7768 - acc: 0.2013 - val_loss: 2.4566 - val_acc: 0.2938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15735f828>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(embed_matrix), len(embed_matrix.columns), input_length=MAXLEN, weights=[random_matrix],\n",
    "                           trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(MAXLEN,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(target.shape[1], activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, output)\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=1e-3, decay=1e-5)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "model.fit(data, target, validation_split=0.2, epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
